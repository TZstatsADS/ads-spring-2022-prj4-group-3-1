{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c70a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import scipy.optimize as optim\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "# this function returns the distance matrix\n",
    "def distances(X, v, alpha, N, P, k):\n",
    "    dists = np.zeros((N, k))\n",
    "    for i in range(N):\n",
    "        for p in range(P):\n",
    "            for j in range(k):    \n",
    "                dists[i, j] += (X[i, p] - v[j, p]) * (X[i, p] - v[j, p]) * alpha[p]\n",
    "    return dists\n",
    "\n",
    "# this function returns the M_nk\n",
    "def M_nk(dists, N, k):\n",
    "    M_nk = np.zeros((N, k))\n",
    "    exp = np.zeros((N, k))\n",
    "    denom = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            exp[i, j] = np.exp(-1 * dists[i, j])\n",
    "            denom[i] += exp[i, j]\n",
    "        for j in range(k):\n",
    "            if denom[i]:\n",
    "                M_nk[i, j] = exp[i, j] / denom[i]\n",
    "            else:\n",
    "                M_nk[i, j] = exp[i, j] / 1e-6\n",
    "    return M_nk\n",
    " \n",
    "# this function returns the M_k array\n",
    "def M_k(M_nk, N, k):\n",
    "    M_k = np.zeros(k)\n",
    "    for j in range(k):\n",
    "        for i in range(N):\n",
    "            M_k[j] += M_nk[i, j]\n",
    "        M_k[j] /= N\n",
    "    return M_k\n",
    "\n",
    "# this function reconstructs of X to x_n_hat and L_x\n",
    "def x_n_hat(X, M_nk, v, N, P, k):\n",
    "    x_n_hat = np.zeros((N, P))\n",
    "    L_x = 0.0\n",
    "    for i in range(N):\n",
    "        for p in range(P):\n",
    "            for j in range(k):\n",
    "                x_n_hat[i, p] += M_nk[i, j] * v[j, p]\n",
    "            L_x += (X[i, p] - x_n_hat[i, p]) * (X[i, p] - x_n_hat[i, p])\n",
    "    return x_n_hat, L_x\n",
    "\n",
    "# this function returns a list of prediction\n",
    "def yhat(M_nk, y, w, N, k):\n",
    "    yhat = np.zeros(N)\n",
    "    L_y = 0.0\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            yhat[i] += M_nk[i, j] * w[j]\n",
    "        yhat[i] = 1e-6 if yhat[i] <= 0 else yhat[i]\n",
    "        yhat[i] = 0.999 if yhat[i] >= 1 else yhat[i]\n",
    "        L_y += -1 * y[i] * np.log(yhat[i]) - (1.0 - y[i]) * np.log(1.0 - yhat[i])\n",
    "    return yhat, L_y\n",
    "\n",
    "\n",
    "# this function returns the objective function we want to minimize\n",
    "def LFR_objective(params, data_sensitive, data_nonsensitive, y_sensitive, \n",
    "        y_nonsensitive,  k=10, A_x = 1e-4, A_y = 0.1, A_z = 1000):\n",
    "    LFR_objective.iters += 1 \n",
    "    Ns, P = data_sensitive.shape\n",
    "    Nns, _ = data_nonsensitive.shape\n",
    "    \n",
    "    alpha0 = params[:P]\n",
    "    alpha1 = params[P : 2 * P]\n",
    "    w = params[2 * P : (2 * P) + k]\n",
    "    v = np.matrix(params[(2 * P) + k:]).reshape((k, P))\n",
    "        \n",
    "    dists_sensitive = distances(data_sensitive, v, alpha0, Ns, P, k)\n",
    "    dists_nonsensitive = distances(data_nonsensitive, v, alpha1, Nns, P, k)\n",
    "\n",
    "    M_nk_sensitive = M_nk(dists_sensitive, Ns, k)\n",
    "    M_nk_nonsensitive = M_nk(dists_nonsensitive, Nns, k)\n",
    "    \n",
    "    M_k_sensitive = M_k(M_nk_sensitive, Ns, k)\n",
    "    M_k_nonsensitive = M_k(M_nk_nonsensitive, Nns, k)\n",
    "    \n",
    "    L_z = 0.0\n",
    "    for j in range(k):\n",
    "        L_z += abs(M_k_sensitive[j] - M_k_nonsensitive[j])\n",
    "\n",
    "    x_n_hat_sensitive, L_x_sen = x_n_hat(data_sensitive, M_nk_sensitive, v, Ns, P, k)\n",
    "    x_n_hat_nonsensitive, L_x_nsen = x_n_hat(data_nonsensitive, M_nk_nonsensitive, v, Nns, P, k)\n",
    "    L_x = L_x_sen + L_x_nsen\n",
    "\n",
    "    yhat_sensitive, L_y_sen = yhat(M_nk_sensitive, y_sensitive, w, Ns, k)\n",
    "    yhat_nonsensitive, L_y_nsen = yhat(M_nk_nonsensitive, y_nonsensitive, w, Nns, k)\n",
    "    L_y = L_y_sen + L_y_nsen\n",
    "\n",
    "    objective = A_x * L_x + A_y * L_y + A_z * L_z\n",
    "\n",
    "    return objective\n",
    "\n",
    "LFR_objective.iters = 0\n",
    "\n",
    "def LFR(X_train_s, X_train_n, y_train_s, y_train_n, K=10, A_x = 1e-4, A_y = 0.1, A_z = 1000, iter = 100):\n",
    "    rez = np.random.uniform(size=X_train_s.shape[1] * 2 + K + X_train_s.shape[1] * K)\n",
    "    bnd = []\n",
    "    for i, k2 in enumerate(rez):\n",
    "        if i < X_train_s.shape[1] * 2 or i >= X_train_s.shape[1] * 2 + K:\n",
    "            bnd.append((None, None))\n",
    "        else:\n",
    "            bnd.append((0, 1))\n",
    "    \n",
    "    # minimize the metric by parameters alpha, w and v\n",
    "    para, min_L, d = optim.fmin_l_bfgs_b(LFR_objective, x0=rez, epsilon=1e-5, \n",
    "                                         args=(X_train_s, X_train_n, y_train_s, y_train_n, K, A_z, A_x, A_y), \n",
    "                                         bounds = bnd, approx_grad=True, \n",
    "                                         maxfun=iter, maxiter=iter)\n",
    "    \n",
    "    return para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6b2ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
